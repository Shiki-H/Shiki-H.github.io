<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="keyword"  content="">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>Stacking with Bayesian Optimization - </title>

    <link rel="canonical" href="http://localhost:4000/2017/11/08/Stacking-Template/">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/hux-blog.min.css">

    <!-- Pygments Github CSS -->
    <link rel="stylesheet" href="/css/syntax.css">

    <!-- Custom Fonts -->
    <!-- <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
    <!-- Hux change font-awesome CDN to qiniu -->
    <link href="http://cdn.staticfile.org/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">


    <!-- Hux Delete, sad but pending in China
    <link href='http://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/
    css'>
    -->


    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- ga & ba script hoook -->
    <script></script>
</head>


<!-- hack iOS CSS :active style -->
<body ontouchstart="">

    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Shiki's Blog</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <!-- Known Issue, found by Hux:
            <nav>'s height woule be hold on by its content.
            so, when navbar scale out, the <nav> will cover tags.
            also mask any touch event of tags, unfortunately.
        -->
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>
                    
                    <li>
                        <a href="/about/">About</a>
                    </li>
                    
                    <li>
                        <a href="/tags/">Tags</a>
                    </li>
                    
                </ul>
            </div>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>
<script>
    // Drop Bootstarp low-performance Navbar
    // Use customize navbar with high-quality material design animation
    // in high-perf jank-free CSS3 implementation
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        // CLOSE
            $navbar.className = " ";
            // wait until animation end.
            setTimeout(function(){
                // prevent frequently toggle
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        // OPEN
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>


    <!-- Image to hack wechat -->
<!-- <img src="/img/icon_wechat.png" width="0" height="0"> -->
<!-- <img src="/img/default.jpg" width="0" height="0"> -->

<!-- Post Header -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script
  type="text/javascript"
  charset="utf-8"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"
>
</script>
<script
  type="text/javascript"
  charset="utf-8"
  src="https://vincenttam.github.io/javascripts/MathJaxLocal.js"
>
</script>

<style type="text/css">
    header.intro-header{
        background-image: url('/img/default.jpg')
    }
</style>
<header class="intro-header" >
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <div class="tags">
                        
                        <a class="tag" href="/tags/#python" title="python">python</a>
                        
                    </div>
                    <h1>Stacking with Bayesian Optimization</h1>
                    
                    
                    <h2 class="subheading"></h2>
                    
                    <span class="meta">Posted by Shiki on November 8, 2017</span>
                </div>
            </div>
        </div>
    </div>
</header>

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

    <!-- Post Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

				<h2 id="introduction">Introduction</h2>

<p>Stacking has become a common practice in machine learning competitions such as Kaggle. Here is a simple stacking template based on the model I used in Alibab Tianchi competition. This template incorporates bayesian optimization, which will save you the time spent on grid searching hyper-parameters.</p>

<p>As a disclaimer, since I am using random data generated by <code class="highlighter-rouge">sklearn</code>, the performance of the stacking model may vary. Again, since this is just for illustration, I copied the parameter range from my original model, which may not be optimal. In addition, to obtain decent results from bayesian optimization, you should increase the number of iterations and combine with your experience when setting the range for hyper-parameters.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s">'ignore'</span><span class="p">)</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s">'display.max_columns'</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="load-data">Load Data</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">KFold</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># generate random samples for inllustration</span>
<span class="c"># we will work with an imbalanced data set </span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> 
                           <span class="n">n_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
                           <span class="n">n_features</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
                           <span class="n">n_informative</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
                           <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">],</span>
                           <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> \
                <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="stacking-preparations">Stacking Preparations</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Set up parameters</span>
<span class="n">ntrain</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">ntest</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">SEED</span> <span class="o">=</span> <span class="mi">42</span> 
<span class="n">NFOLDS</span> <span class="o">=</span> <span class="mi">5</span> 
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">ntrain</span><span class="p">,</span> <span class="n">n_folds</span><span class="o">=</span> <span class="n">NFOLDS</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
</code></pre></div></div>

<p>There are quite a few ways to train meta-features for stacking model. I have tried a few and eventually decided to stay with the one mentioned by <a href="https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python/">Anisotropdc</a>, which is to compute predictions on test set using base model trained on each fold and then take average. Based on my experience, this method gives the best performance comparing to other simple stacking methods. If you are interested in fancier methods, you may want to take a look <a href="https://link.springer.com/content/pdf/10.1023%2FB%3AMACH.0000015881.36452.6e.pdf">here</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Function to obtain out-of-fold prediction</span>
<span class="k">def</span> <span class="nf">get_oof</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">):</span>
    <span class="n">oof_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">ntrain</span><span class="p">,))</span>
    <span class="n">oof_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">ntest</span><span class="p">,))</span>
    <span class="n">oof_test_skf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">NFOLDS</span><span class="p">,</span> <span class="n">ntest</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">kf</span><span class="p">):</span>
        <span class="n">x_tr</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">train_index</span><span class="p">]</span>
        <span class="n">y_tr</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">train_index</span><span class="p">]</span>
        <span class="n">x_te</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>

        <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_tr</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">)</span>

        <span class="n">oof_train</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_te</span><span class="p">)</span>
        <span class="n">oof_test_skf</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>

    <span class="n">oof_test</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">oof_test_skf</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">oof_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">oof_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="tuning-base-models">Tuning Base Models</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span>

<span class="c"># bayesian optimization</span>
<span class="kn">from</span> <span class="nn">bayes_opt</span> <span class="kn">import</span> <span class="n">BayesianOptimization</span>

<span class="c"># base models</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">lightgbm</span> <span class="kn">import</span> <span class="n">LGBMClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">LinearSVC</span>
<span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span>

<span class="c"># second layer model</span>
<span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>
</code></pre></div></div>

<p>For large data sets, tuning each base model can take a very long time. To prevent any accidental failure, I recommend saving the models (or to be more specific, the parameters of the models) immediately when the tuning is done.</p>

<p>To save and load your model, you can use sklearnâ€™s joblib.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># save model</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>

<span class="c"># load model</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.externals</span> <span class="kn">import</span> <span class="n">joblib</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">gmtime</span><span class="p">,</span> <span class="n">strftime</span>
<span class="kn">import</span> <span class="nn">json</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># parameters for bayesian optimization</span>
<span class="n">gp_params</span> <span class="o">=</span> <span class="p">{</span><span class="s">"alpha"</span><span class="p">:</span> <span class="mf">1e-5</span><span class="p">}</span>
<span class="n">n_iter</span><span class="o">=</span><span class="mi">5</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Function to generate file name based completion time</span>
<span class="k">def</span> <span class="nf">generate_filename</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="o">+</span><span class="n">strftime</span><span class="p">(</span><span class="s">"</span><span class="si">%</span><span class="s">Y-</span><span class="si">%</span><span class="s">m-</span><span class="si">%</span><span class="s">d_</span><span class="si">%</span><span class="s">H:</span><span class="si">%</span><span class="s">M"</span><span class="p">,</span> <span class="n">gmtime</span><span class="p">())</span><span class="o">+</span><span class="s">'.pkl'</span>

<span class="c"># Function to save the log of parameter tuning</span>
<span class="k">def</span> <span class="nf">BO_log</span><span class="p">(</span><span class="n">BO</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
    <span class="n">fname</span> <span class="o">=</span> <span class="n">name</span> <span class="o">+</span> <span class="n">strftime</span><span class="p">(</span><span class="s">"</span><span class="si">%</span><span class="s">Y-</span><span class="si">%</span><span class="s">m-</span><span class="si">%</span><span class="s">d_</span><span class="si">%</span><span class="s">H:</span><span class="si">%</span><span class="s">M"</span><span class="p">,</span> <span class="n">gmtime</span><span class="p">())</span> <span class="o">+</span> <span class="s">'.json'</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
        <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">BO</span><span class="o">.</span><span class="n">res</span><span class="p">,</span> <span class="n">fp</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">fname</span> <span class="o">+</span> <span class="s">' saved'</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="random-forest">Random Forest</h4>

<p>Since we are dealing with imbalanced data, we need to be careful in model training. In the past, my colleagues and I have tried every popular sampling methods (over-sampling, under-sampling, and SMOTE) but in the end we decided to adjust the class directly. There are a few advantages of this method: 1) it is easy to do; 2) it does not make any assumptions on the distribution of the features; 3) when it is not clear what weight you should assign to each class, you can treat it as a hyper-parameter and let machine do the work for you.</p>

<p>Regarding the metrics used for optimization, I am using f1 score since this was the judging criteria of the competition I participated in. Of course you can use any metric you wish, but keep in mind that when you are dealing imbalanced data, you have to be careful with your choice.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">rfc</span><span class="p">(</span><span class="n">n_estimators</span><span class="p">,</span> <span class="n">min_samples_split</span><span class="p">,</span> <span class="n">max_depth</span><span class="p">,</span> <span class="n">class_weight</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">n_estimators</span><span class="p">),</span>
            <span class="n">min_samples_split</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">min_samples_split</span><span class="p">),</span>
            <span class="n">max_depth</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">max_depth</span><span class="p">),</span>
            <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">bootstrap</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
            <span class="n">class_weight</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="n">class_weight</span><span class="p">}</span>
        <span class="p">)</span>
<span class="k">def</span> <span class="nf">rfccv</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">):</span>
    <span class="n">val</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span>
        <span class="n">rfc</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">),</span>
        <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'f1'</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span>
    <span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">val</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rfcBO</span> <span class="o">=</span> <span class="n">BayesianOptimization</span><span class="p">(</span>
        <span class="n">rfccv</span><span class="p">,</span>
        <span class="p">{</span><span class="s">'n_estimators'</span><span class="p">:</span> <span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">500</span><span class="p">),</span>
        <span class="s">'min_samples_split'</span><span class="p">:</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">25</span><span class="p">),</span>
        <span class="s">'max_depth'</span><span class="p">:</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">12</span><span class="p">),</span>
        <span class="s">'class_weight'</span><span class="p">:</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="p">}</span>
    <span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rfcBO</span><span class="o">.</span><span class="n">maximize</span><span class="p">(</span><span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter</span><span class="p">,</span> <span class="o">**</span><span class="n">gp_params</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">BO_log</span><span class="p">(</span><span class="n">rfcBO</span><span class="p">,</span> <span class="s">'rfc'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rf_clf</span> <span class="o">=</span> <span class="n">rfc</span><span class="p">(</span><span class="o">**</span><span class="n">rfcBO</span><span class="o">.</span><span class="n">res</span><span class="p">[</span><span class="s">'max'</span><span class="p">][</span><span class="s">'max_params'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">rf_clf</span><span class="p">,</span> <span class="n">generate_filename</span><span class="p">(</span><span class="s">'rf_clf'</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rf_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">rf_pred</span> <span class="o">=</span> <span class="n">rf_clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">rf_pred</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rf_oof_train</span><span class="p">,</span> <span class="n">rf_oof_test</span> <span class="o">=</span> <span class="n">get_oof</span><span class="p">(</span><span class="n">rf_clf</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="lightgbm">LightGBM</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">lgb</span><span class="p">(</span><span class="n">n_estimators</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">scale_pos_weight</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">LGBMClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">n_estimators</span><span class="p">),</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="n">scale_pos_weight</span><span class="o">=</span><span class="n">scale_pos_weight</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="mi">42</span>
        <span class="p">)</span>
<span class="k">def</span> <span class="nf">lgbcv</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">):</span>
    <span class="n">val</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span>
        <span class="n">lgb</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">),</span>
        <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'f1'</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span>
    <span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">val</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lgbcBO</span> <span class="o">=</span> <span class="n">BayesianOptimization</span><span class="p">(</span>
        <span class="n">lgbcv</span><span class="p">,</span>
        <span class="p">{</span><span class="s">'n_estimators'</span><span class="p">:</span> <span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">500</span><span class="p">),</span>
         <span class="s">'learning_rate'</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span>
         <span class="s">'scale_pos_weight'</span><span class="p">:</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="p">}</span>
    <span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lgbcBO</span><span class="o">.</span><span class="n">maximize</span><span class="p">(</span><span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter</span><span class="p">,</span> <span class="o">**</span><span class="n">gp_params</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">BO_log</span><span class="p">(</span><span class="n">lgbcBO</span><span class="p">,</span> <span class="s">'lgb'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lgb_clf</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">(</span><span class="o">**</span><span class="n">lgbcBO</span><span class="o">.</span><span class="n">res</span><span class="p">[</span><span class="s">'max'</span><span class="p">][</span><span class="s">'max_params'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">lgb_clf</span><span class="p">,</span> <span class="n">generate_filename</span><span class="p">(</span><span class="s">'lgb_clf'</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lgb_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">lgb_pred</span> <span class="o">=</span> <span class="n">lgb_clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">lgb_pred</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lgb_oof_train</span><span class="p">,</span> <span class="n">lgb_oof_test</span> <span class="o">=</span> <span class="n">get_oof</span><span class="p">(</span><span class="n">lgb_clf</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">)</span> 
</code></pre></div></div>

<h4 id="svm">SVM</h4>

<p>We need to normalize data first before training SVM and MLP.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x_train_scaled</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
<span class="n">x_test_scaled</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">linsvc</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">class_weight</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">LinearSVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="n">C</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
            <span class="n">class_weight</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="n">class_weight</span><span class="p">}</span>
        <span class="p">)</span>
<span class="k">def</span> <span class="nf">linsvccv</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">):</span>
    <span class="n">val</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span>
        <span class="n">linsvc</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">),</span>
        <span class="n">x_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'f1'</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>
    <span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">val</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">linsvcBO</span> <span class="o">=</span> <span class="n">BayesianOptimization</span><span class="p">(</span>
        <span class="n">linsvccv</span><span class="p">,</span>
        <span class="p">{</span><span class="s">'C'</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10000</span><span class="p">),</span>
         <span class="s">'class_weight'</span><span class="p">:</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">)}</span>
    <span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">linsvcBO</span><span class="o">.</span><span class="n">maximize</span><span class="p">(</span><span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter</span><span class="p">,</span> <span class="o">**</span><span class="n">gp_params</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">BO_log</span><span class="p">(</span><span class="n">linsvcBO</span><span class="p">,</span> <span class="s">'linsvc'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">linsvc_clf</span> <span class="o">=</span> <span class="n">linsvc</span><span class="p">(</span><span class="o">**</span><span class="n">linsvcBO</span><span class="o">.</span><span class="n">res</span><span class="p">[</span><span class="s">'max'</span><span class="p">][</span><span class="s">'max_params'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">linsvc_clf</span><span class="p">,</span> <span class="n">generate_filename</span><span class="p">(</span><span class="s">'linsvc_clf'</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">linsvc_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">linsvc_pred</span> <span class="o">=</span> <span class="n">linsvc_clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test_scaled</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">linsvc_pred</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">linsvc_oof_train</span><span class="p">,</span> <span class="n">linsvc_oof_test</span> <span class="o">=</span> <span class="n">get_oof</span><span class="p">(</span><span class="n">linsvc_clf</span><span class="p">,</span><span class="n">x_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test_scaled</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="mlp">MLP</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">mlp</span><span class="p">(</span><span class="n">first_layer</span><span class="p">,</span> <span class="n">second_layer</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">MLPClassifier</span><span class="p">(</span>
            <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">first_layer</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">second_layer</span><span class="p">)),</span>
            <span class="n">alpha</span><span class="o">=</span><span class="mi">10</span><span class="o">**</span><span class="n">alpha</span>
        <span class="p">)</span>
<span class="k">def</span> <span class="nf">mlpccv</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">):</span>
    <span class="n">val</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span>
        <span class="n">mlp</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">),</span>
        <span class="n">x_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'f1'</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>
    <span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">val</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mlpcBO</span> <span class="o">=</span> <span class="n">BayesianOptimization</span><span class="p">(</span>
        <span class="n">mlpccv</span><span class="p">,</span>
        <span class="p">{</span><span class="s">'first_layer'</span><span class="p">:</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span>
         <span class="s">'second_layer'</span><span class="p">:</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
         <span class="s">'alpha'</span><span class="p">:</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)}</span>
    <span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mlpcBO</span><span class="o">.</span><span class="n">maximize</span><span class="p">(</span><span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter</span><span class="p">,</span> <span class="o">**</span><span class="n">gp_params</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">BO_log</span><span class="p">(</span><span class="n">mlpcBO</span><span class="p">,</span> <span class="s">'mlp'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mlp_clf</span> <span class="o">=</span> <span class="n">mlp</span><span class="p">(</span><span class="o">**</span><span class="n">mlpcBO</span><span class="o">.</span><span class="n">res</span><span class="p">[</span><span class="s">'max'</span><span class="p">][</span><span class="s">'max_params'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">mlp_clf</span><span class="p">,</span> <span class="n">generate_filename</span><span class="p">(</span><span class="s">'mlp_clf'</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mlp_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">mlp_pred</span> <span class="o">=</span> <span class="n">mlp_clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test_scaled</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">mlp_pred</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mlp_oof_train</span><span class="p">,</span> <span class="n">mlp_oof_test</span> <span class="o">=</span> <span class="n">get_oof</span><span class="p">(</span><span class="n">mlp_clf</span><span class="p">,</span> <span class="n">x_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test_scaled</span><span class="p">)</span> 
</code></pre></div></div>

<h2 id="stacking-base-models">Stacking Base Models</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">base_predictions_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">{</span><span class="s">'RandomForest'</span><span class="p">:</span> <span class="n">rf_oof_train</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
     <span class="s">'LightGBM'</span><span class="p">:</span> <span class="n">lgb_oof_train</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
     <span class="s">'LinSVC'</span><span class="p">:</span> <span class="n">linsvc_oof_train</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
     <span class="s">'MLP'</span><span class="p">:</span> <span class="n">mlp_oof_train</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
    <span class="p">})</span>
<span class="n">base_predictions_train</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>LightGBM</th>
      <th>LinSVC</th>
      <th>MLP</th>
      <th>RandomForest</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">base_predictions_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
            <span class="n">xticklabels</span><span class="o">=</span><span class="n">base_predictions_train</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span>
            <span class="n">yticklabels</span><span class="o">=</span><span class="n">base_predictions_train</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span>
            <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/img/in-post/stacking-template/output_58_1.png" alt="png" /></p>

<p>This heat map was taken from one of the randomly generated data I have run. In general, as mentioned by <a href="https://link.springer.com/content/pdf/10.1023%2FB%3AMACH.0000015881.36452.6e.pdf">DÅ¾eroski and Å½enko</a>, it is a good idea to include heterogenous classifiers as base models for stacking, i.e. classifiers that use different model representations. Since both random forest and lightgbm are tree-based, their high correlation is expected.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">xg_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">rf_oof_train</span><span class="p">,</span> 
                           <span class="n">lgb_oof_train</span><span class="p">,</span> 
                           <span class="n">linsvc_oof_train</span><span class="p">,</span> 
                           <span class="n">mlp_oof_train</span><span class="p">,</span> 
                          <span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">xg_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">rf_oof_test</span><span class="p">,</span> 
                          <span class="n">lgb_oof_test</span><span class="p">,</span> 
                          <span class="n">linsvc_oof_test</span><span class="p">,</span> 
                          <span class="n">mlp_oof_test</span><span class="p">,</span> 
                         <span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">xgb</span><span class="p">(</span><span class="n">max_depth</span><span class="p">,</span> 
          <span class="n">learning_rate</span><span class="p">,</span> 
          <span class="n">n_estimators</span><span class="p">,</span> 
          <span class="n">gamma</span><span class="p">,</span> 
          <span class="n">min_child_weight</span><span class="p">,</span> 
          <span class="n">subsample</span><span class="p">,</span>
          <span class="n">scale_pos_weight</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">XGBClassifier</span><span class="p">(</span>
            <span class="n">max_depth</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">max_depth</span><span class="p">),</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="n">n_estimators</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">n_estimators</span><span class="p">),</span>
            <span class="n">min_child_weight</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">min_child_weight</span><span class="p">),</span>
            <span class="n">gamma</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">gamma</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
            <span class="n">subsample</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">subsample</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">0</span><span class="p">),</span>
            <span class="n">scale_pos_weight</span><span class="o">=</span><span class="n">scale_pos_weight</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>
        <span class="p">)</span>
<span class="k">def</span> <span class="nf">xgbcv</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">):</span>
    <span class="n">val</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span>
        <span class="n">xgb</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">),</span>
        <span class="n">xg_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'f1'</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span>
    <span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">val</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">xgbBO</span> <span class="o">=</span> <span class="n">BayesianOptimization</span><span class="p">(</span>
        <span class="n">xgbcv</span><span class="p">,</span>
        <span class="p">{</span><span class="s">'max_depth'</span><span class="p">:</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
         <span class="s">'learning_rate'</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">),</span>
         <span class="s">'n_estimators'</span><span class="p">:(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">500</span><span class="p">),</span>
         <span class="s">'min_child_weight'</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span>
         <span class="s">'gamma'</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
         <span class="s">'subsample'</span><span class="p">:(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
         <span class="s">'scale_pos_weight'</span><span class="p">:(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="p">}</span>
    <span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">xgbBO</span><span class="o">.</span><span class="n">maximize</span><span class="p">(</span><span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter</span><span class="p">,</span> <span class="o">**</span><span class="n">gp_params</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">BO_log</span><span class="p">(</span><span class="n">xgbBO</span><span class="p">,</span> <span class="s">'xgb'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">xgb_clf</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">(</span><span class="o">**</span><span class="n">xgbBO</span><span class="o">.</span><span class="n">res</span><span class="p">[</span><span class="s">'max'</span><span class="p">][</span><span class="s">'max_params'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">xgb_clf</span><span class="p">,</span> <span class="n">generate_filename</span><span class="p">(</span><span class="s">'xgb_clf'</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">xgb_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xg_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">xgb_pred</span> <span class="o">=</span> <span class="n">xgb_clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xg_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">xgb_pred</span><span class="p">))</span>
</code></pre></div></div>

<h2 id="conclusion">Conclusion</h2>

<p>The aim of this template is to provide a quick startup on setting up a stacking ensemble with bayesian optimization. Based on my work experience in fraud detection, finding the right feature is much more important than building a fancy model. As the saying goes, <em>garbage in, garbage out</em>. I hope this template can save you some time in setting up models and tuning hyper-parameters so as to focus on understanding the problem.</p>


                <hr>

                


                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/2017/11/07/3D-Interactive-Visualization-of-Graph/" data-toggle="tooltip" data-placement="top" title="3D Interactive Visualization of Graph">&larr; Previous Post</a>
                    </li>
                    
                    
                </ul>


                

                

            </div>

    <!-- Sidebar Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                <!-- Featured Tags -->
                

                <!-- Friends Blog -->
                
            </div>
        </div>
    </div>
</article>








<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>
<!-- anchor-js, Doc:http://bryanbraun.github.io/anchorjs/ -->
<script>
    async("http://cdn.bootcss.com/anchor-js/1.1.1/anchor.min.js",function(){
        anchors.options = {
          visible: 'always',
          placement: 'right',
          icon: '#'
        };
        anchors.add().remove('.intro-header h1').remove('.subheading').remove('.sidebar-container h5');
    })
</script>
<style>
    /* place left on bigger screen */
    @media all and (min-width: 800px) {
        .anchorjs-link{
            position: absolute;
            left: -0.75em;
            font-size: 1.1em;
            margin-top : -0.1em;
        }
    }
</style>



    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                    
                    

                    <!-- add Weibo, Zhihu by Hux, add target = "_blank" to <a> by Hux -->
                    
                    


                    
                    
                </ul>
                <p class="copyright text-muted">
                    Copyright &copy; Shiki's Blog 2017
                    <br>
                    Theme by <a href="http://huangxuan.me">Hux</a> |
                    <iframe
                        style="margin-left: 2px; margin-bottom:-5px;"
                        frameborder="0" scrolling="0" width="91px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=huxpro&repo=huxpro.github.io&type=star&count=true" >
                    </iframe>
                </p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="/js/jquery.min.js "></script>

<!-- Bootstrap Core JavaScript -->
<script src="/js/bootstrap.min.js "></script>

<!-- Custom Theme JavaScript -->
<script src="/js/hux-blog.min.js "></script>


<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>

<!-- 
     Because of the native support for backtick-style fenced code blocks 
     right within the Markdown is landed in Github Pages, 
     From V1.6, There is no need for Highlight.js, 
     so Huxblog drops it officially.

     - https://github.com/blog/2100-github-pages-now-faster-and-simpler-with-jekyll-3-0  
     - https://help.github.com/articles/creating-and-highlighting-code-blocks/    
-->
<!--
    <script>
        async("http://cdn.bootcss.com/highlight.js/8.6/highlight.min.js", function(){
            hljs.initHighlightingOnLoad();
        })
    </script>
    <link href="http://cdn.bootcss.com/highlight.js/8.6/styles/github.min.css" rel="stylesheet">
-->


<!-- jquery.tagcloud.js -->
<script>
    // only load tagcloud.js in tag.html
    if($('#tag_cloud').length !== 0){
        async("/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                //size: {start: 1, end: 1, unit: 'em'},
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>

<!--fastClick.js -->
<script>
    async("http://cdn.bootcss.com/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>


<!-- Google Analytics -->



<!-- Baidu Tongji -->




<!-- Image to hack wechat -->
<!--<img src="/img/icon_wechat.png" width="0" height="0" />-->
<!-- Migrate from head to bottom, no longer block render and still work -->

</body>

</html>
