
<!doctype html>














<html class="theme-next mist" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/assets/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/assets/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/assets/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="python,machine learning," />








  <link rel="shortcut icon" type="image/x-icon" href="/assets/favicon.ico?v=5.1.1" />
















<meta name="description" content="Introduction">
<meta name="keywords" content="python, machine learning">
<meta property="og:type" content="article">
<meta property="og:title" content="Stacking with Bayesian Optimization">
<meta property="og:url" content="http://localhost:4000/2017/11/08/Stacking-Template/">
<meta property="og:site_name" content="Random Notes">
<meta property="og:description" content="Introduction">
<meta property="og:locale" content="en">
<meta property="og:image" content="/img/in-post/stacking-template/output_58_1.png">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Stacking with Bayesian Optimization">
<meta name="twitter:description" content="Introduction">
<meta name="twitter:image" content="/img/in-post/stacking-template/output_58_1.png">


<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: false,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://localhost:4000/"/>





  <title>Stacking with Bayesian Optimization | Random Notes</title>
  
















</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"> <div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Random Notes</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        processEscapes: true
      }
    });
    </script>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>


<div id="posts" class="posts-expand">
  
  

  

  
  
  

  <article class="post post-type- " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://localhost:4000/2017/11/08/Stacking-Template/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Shiki">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/assets/images/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Random Notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
          
          
            Stacking with Bayesian Optimization
          
        </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-11-08T02:00:00-05:00">
                2017-11-08
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          
            
                <div class="post-description">
                    
                </div>
            
          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
  
  












  <h2 id="introduction">Introduction</h2>

<p>Stacking has become a common practice in machine learning competitions such as Kaggle. Here is a simple stacking template based on the model I used in Alibab Tianchi competition. This template incorporates bayesian optimization, which will save you the time spent on grid searching hyper-parameters. I have uploaded my template notebook <a href="https://github.com/Shiki-H/stacking-template/blob/master/Stacking%20Template.ipynb">here</a>.</p>

<p>As a disclaimer, since I am using random data generated by <code class="highlighter-rouge">sklearn</code>, the performance of the stacking model may vary. Again, since this is just for illustration, I copied the parameter range from my original model, which may not be optimal. In addition, to obtain decent results from bayesian optimization, you should increase the number of iterations and combine with your experience when setting the range for hyper-parameters.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3<br/>4<br/>5<br/>6<br/>7<br/>8</pre></td><td class="code"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="kn">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s">'ignore'</span><span class="p">)</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s">'display.max_columns'</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
</code></pre></td></tr></tbody></table></div>
</div>

<h2 id="load-data">Load Data</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3</pre></td><td class="code"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">KFold</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3<br/>4<br/>5<br/>6<br/>7<br/>8</pre></td><td class="code"><pre class="highlight"><code><span class="c"># generate random samples for inllustration</span>
<span class="c"># we will work with an imbalanced data set </span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> 
                           <span class="n">n_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
                           <span class="n">n_features</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
                           <span class="n">n_informative</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
                           <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">],</span>
                           <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2</pre></td><td class="code"><pre class="highlight"><code><span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> \
                <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</code></pre></td></tr></tbody></table></div>
</div>

<h2 id="stacking-preparations">Stacking Preparations</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3<br/>4<br/>5<br/>6</pre></td><td class="code"><pre class="highlight"><code><span class="c"># Set up parameters</span>
<span class="n">ntrain</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">ntest</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">SEED</span> <span class="o">=</span> <span class="mi">42</span> 
<span class="n">NFOLDS</span> <span class="o">=</span> <span class="mi">5</span> 
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">ntrain</span><span class="p">,</span> <span class="n">n_folds</span><span class="o">=</span> <span class="n">NFOLDS</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
</code></pre></td></tr></tbody></table></div>
</div>

<p>There are quite a few ways to train meta-features for stacking model. I have tried a few and eventually decided to stay with the one mentioned by <a href="https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python/">Anisotropdc</a>, which is to compute predictions on test set using base model trained on each fold and then take average. Based on my experience, this method gives the best performance comparing to other simple stacking methods. If you are interested in fancier methods, you may want to take a look <a href="https://link.springer.com/content/pdf/10.1023%2FB%3AMACH.0000015881.36452.6e.pdf">here</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3<br/>4<br/>5<br/>6<br/>7<br/>8<br/>9<br/>10<br/>11<br/>12<br/>13<br/>14<br/>15<br/>16<br/>17<br/>18</pre></td><td class="code"><pre class="highlight"><code><span class="c"># Function to obtain out-of-fold prediction</span>
<span class="k">def</span> <span class="nf">get_oof</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">):</span>
    <span class="n">oof_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">ntrain</span><span class="p">,))</span>
    <span class="n">oof_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">ntest</span><span class="p">,))</span>
    <span class="n">oof_test_skf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">NFOLDS</span><span class="p">,</span> <span class="n">ntest</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">kf</span><span class="p">):</span>
        <span class="n">x_tr</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">train_index</span><span class="p">]</span>
        <span class="n">y_tr</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">train_index</span><span class="p">]</span>
        <span class="n">x_te</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>

        <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_tr</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">)</span>

        <span class="n">oof_train</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_te</span><span class="p">)</span>
        <span class="n">oof_test_skf</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>

    <span class="n">oof_test</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">oof_test_skf</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">oof_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">oof_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></td></tr></tbody></table></div>
</div>

<h2 id="tuning-base-models">Tuning Base Models</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3<br/>4<br/>5<br/>6<br/>7<br/>8<br/>9<br/>10<br/>11<br/>12<br/>13<br/>14</pre></td><td class="code"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span>

<span class="c"># bayesian optimization</span>
<span class="kn">from</span> <span class="nn">bayes_opt</span> <span class="kn">import</span> <span class="n">BayesianOptimization</span>

<span class="c"># base models</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">lightgbm</span> <span class="kn">import</span> <span class="n">LGBMClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">LinearSVC</span>
<span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span>

<span class="c"># second layer model</span>
<span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>
</code></pre></td></tr></tbody></table></div>
</div>

<p>For large data sets, tuning each base model can take a very long time. To prevent any accidental failure, I recommend saving the models (or to be more specific, the parameters of the models) immediately when the tuning is done.</p>

<p>To save and load your model, you can use sklearn’s <code class="highlighter-rouge">joblib</code>.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3<br/>4<br/>5</pre></td><td class="code"><pre class="highlight"><code><span class="c"># save model</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>

<span class="c"># load model</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3</pre></td><td class="code"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.externals</span> <span class="kn">import</span> <span class="n">joblib</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">gmtime</span><span class="p">,</span> <span class="n">strftime</span>
<span class="kn">import</span> <span class="nn">json</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3</pre></td><td class="code"><pre class="highlight"><code><span class="c"># parameters for bayesian optimization</span>
<span class="n">gp_params</span> <span class="o">=</span> <span class="p">{</span><span class="s">"alpha"</span><span class="p">:</span> <span class="mf">1e-5</span><span class="p">}</span>
<span class="n">n_iter</span><span class="o">=</span><span class="mi">5</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3<br/>4<br/>5<br/>6<br/>7<br/>8<br/>9<br/>10</pre></td><td class="code"><pre class="highlight"><code><span class="c"># Function to generate file name based completion time</span>
<span class="k">def</span> <span class="nf">generate_filename</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="o">+</span><span class="n">strftime</span><span class="p">(</span><span class="s">"</span><span class="si">%</span><span class="s">Y-</span><span class="si">%</span><span class="s">m-</span><span class="si">%</span><span class="s">d_</span><span class="si">%</span><span class="s">H:</span><span class="si">%</span><span class="s">M"</span><span class="p">,</span> <span class="n">gmtime</span><span class="p">())</span><span class="o">+</span><span class="s">'.pkl'</span>

<span class="c"># Function to save the log of parameter tuning</span>
<span class="k">def</span> <span class="nf">BO_log</span><span class="p">(</span><span class="n">BO</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
    <span class="n">fname</span> <span class="o">=</span> <span class="n">name</span> <span class="o">+</span> <span class="n">strftime</span><span class="p">(</span><span class="s">"</span><span class="si">%</span><span class="s">Y-</span><span class="si">%</span><span class="s">m-</span><span class="si">%</span><span class="s">d_</span><span class="si">%</span><span class="s">H:</span><span class="si">%</span><span class="s">M"</span><span class="p">,</span> <span class="n">gmtime</span><span class="p">())</span> <span class="o">+</span> <span class="s">'.json'</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
        <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">BO</span><span class="o">.</span><span class="n">res</span><span class="p">,</span> <span class="n">fp</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">fname</span> <span class="o">+</span> <span class="s">' saved'</span><span class="p">)</span>
</code></pre></td></tr></tbody></table></div>
</div>

<h4 id="random-forest">Random Forest</h4>

<p>Since we are dealing with imbalanced data, we need to be careful in model training. In the past, my colleagues and I have tried every popular sampling methods (over-sampling, under-sampling, and SMOTE) but in the end we decided to adjust the class weight directly. There are a few advantages of this method: 1) it is easy to do; 2) it does not make any assumptions on the distribution of the features; 3) when it is not clear what weight you should assign to each class, you can treat it as a hyper-parameter and let machine do the work for you.</p>

<p>Regarding the metrics used for optimization, I am using f1 score since this was the judging criteria of the competition I participated in. Of course you can use any metric you wish, but keep in mind that when you are dealing imbalanced data, you have to be careful with your choice.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3<br/>4<br/>5<br/>6<br/>7<br/>8<br/>9<br/>10<br/>11<br/>12<br/>13<br/>14<br/>15</pre></td><td class="code"><pre class="highlight"><code><span class="k">def</span> <span class="nf">rfc</span><span class="p">(</span><span class="n">n_estimators</span><span class="p">,</span> <span class="n">min_samples_split</span><span class="p">,</span> <span class="n">max_depth</span><span class="p">,</span> <span class="n">class_weight</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">n_estimators</span><span class="p">),</span>
            <span class="n">min_samples_split</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">min_samples_split</span><span class="p">),</span>
            <span class="n">max_depth</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">max_depth</span><span class="p">),</span>
            <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">bootstrap</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
            <span class="n">class_weight</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="n">class_weight</span><span class="p">}</span>
        <span class="p">)</span>
<span class="k">def</span> <span class="nf">rfccv</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">):</span>
    <span class="n">val</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span>
        <span class="n">rfc</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">),</span>
        <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'f1'</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span>
    <span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">val</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3<br/>4<br/>5<br/>6<br/>7<br/>8</pre></td><td class="code"><pre class="highlight"><code><span class="n">rfcBO</span> <span class="o">=</span> <span class="n">BayesianOptimization</span><span class="p">(</span>
        <span class="n">rfccv</span><span class="p">,</span>
        <span class="p">{</span><span class="s">'n_estimators'</span><span class="p">:</span> <span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">500</span><span class="p">),</span>
        <span class="s">'min_samples_split'</span><span class="p">:</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">25</span><span class="p">),</span>
        <span class="s">'max_depth'</span><span class="p">:</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">12</span><span class="p">),</span>
        <span class="s">'class_weight'</span><span class="p">:</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="p">}</span>
    <span class="p">)</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1</pre></td><td class="code"><pre class="highlight"><code><span class="n">rfcBO</span><span class="o">.</span><span class="n">maximize</span><span class="p">(</span><span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter</span><span class="p">,</span> <span class="o">**</span><span class="n">gp_params</span><span class="p">)</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1</pre></td><td class="code"><pre class="highlight"><code><span class="n">BO_log</span><span class="p">(</span><span class="n">rfcBO</span><span class="p">,</span> <span class="s">'rfc'</span><span class="p">)</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1</pre></td><td class="code"><pre class="highlight"><code><span class="n">rf_clf</span> <span class="o">=</span> <span class="n">rfc</span><span class="p">(</span><span class="o">**</span><span class="n">rfcBO</span><span class="o">.</span><span class="n">res</span><span class="p">[</span><span class="s">'max'</span><span class="p">][</span><span class="s">'max_params'</span><span class="p">])</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1</pre></td><td class="code"><pre class="highlight"><code><span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">rf_clf</span><span class="p">,</span> <span class="n">generate_filename</span><span class="p">(</span><span class="s">'rf_clf'</span><span class="p">))</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3</pre></td><td class="code"><pre class="highlight"><code><span class="n">rf_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">rf_pred</span> <span class="o">=</span> <span class="n">rf_clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">rf_pred</span><span class="p">))</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1</pre></td><td class="code"><pre class="highlight"><code><span class="n">rf_oof_train</span><span class="p">,</span> <span class="n">rf_oof_test</span> <span class="o">=</span> <span class="n">get_oof</span><span class="p">(</span><span class="n">rf_clf</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">)</span>
</code></pre></td></tr></tbody></table></div>
</div>

<h4 id="lightgbm">LightGBM</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3<br/>4<br/>5<br/>6<br/>7<br/>8<br/>9<br/>10<br/>11<br/>12</pre></td><td class="code"><pre class="highlight"><code><span class="k">def</span> <span class="nf">lgb</span><span class="p">(</span><span class="n">n_estimators</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">scale_pos_weight</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">LGBMClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">n_estimators</span><span class="p">),</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="n">scale_pos_weight</span><span class="o">=</span><span class="n">scale_pos_weight</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="mi">42</span>
        <span class="p">)</span>
<span class="k">def</span> <span class="nf">lgbcv</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">):</span>
    <span class="n">val</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span>
        <span class="n">lgb</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">),</span>
        <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'f1'</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span>
    <span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">val</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3<br/>4<br/>5<br/>6<br/>7</pre></td><td class="code"><pre class="highlight"><code><span class="n">lgbcBO</span> <span class="o">=</span> <span class="n">BayesianOptimization</span><span class="p">(</span>
        <span class="n">lgbcv</span><span class="p">,</span>
        <span class="p">{</span><span class="s">'n_estimators'</span><span class="p">:</span> <span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">500</span><span class="p">),</span>
         <span class="s">'learning_rate'</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span>
         <span class="s">'scale_pos_weight'</span><span class="p">:</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="p">}</span>
    <span class="p">)</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1</pre></td><td class="code"><pre class="highlight"><code><span class="n">lgbcBO</span><span class="o">.</span><span class="n">maximize</span><span class="p">(</span><span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter</span><span class="p">,</span> <span class="o">**</span><span class="n">gp_params</span><span class="p">)</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1</pre></td><td class="code"><pre class="highlight"><code><span class="n">BO_log</span><span class="p">(</span><span class="n">lgbcBO</span><span class="p">,</span> <span class="s">'lgb'</span><span class="p">)</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1</pre></td><td class="code"><pre class="highlight"><code><span class="n">lgb_clf</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">(</span><span class="o">**</span><span class="n">lgbcBO</span><span class="o">.</span><span class="n">res</span><span class="p">[</span><span class="s">'max'</span><span class="p">][</span><span class="s">'max_params'</span><span class="p">])</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1</pre></td><td class="code"><pre class="highlight"><code><span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">lgb_clf</span><span class="p">,</span> <span class="n">generate_filename</span><span class="p">(</span><span class="s">'lgb_clf'</span><span class="p">))</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3</pre></td><td class="code"><pre class="highlight"><code><span class="n">lgb_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">lgb_pred</span> <span class="o">=</span> <span class="n">lgb_clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">lgb_pred</span><span class="p">))</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1</pre></td><td class="code"><pre class="highlight"><code><span class="n">lgb_oof_train</span><span class="p">,</span> <span class="n">lgb_oof_test</span> <span class="o">=</span> <span class="n">get_oof</span><span class="p">(</span><span class="n">lgb_clf</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">)</span> 
</code></pre></td></tr></tbody></table></div>
</div>

<h4 id="svm">SVM</h4>

<p>We need to normalize data first before training SVM and MLP.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1</pre></td><td class="code"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2</pre></td><td class="code"><pre class="highlight"><code><span class="n">x_train_scaled</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
<span class="n">x_test_scaled</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3<br/>4<br/>5<br/>6<br/>7<br/>8<br/>9<br/>10<br/>11</pre></td><td class="code"><pre class="highlight"><code><span class="k">def</span> <span class="nf">linsvc</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">class_weight</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">LinearSVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="n">C</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
            <span class="n">class_weight</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="n">class_weight</span><span class="p">}</span>
        <span class="p">)</span>
<span class="k">def</span> <span class="nf">linsvccv</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">):</span>
    <span class="n">val</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span>
        <span class="n">linsvc</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">),</span>
        <span class="n">x_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'f1'</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>
    <span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">val</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3<br/>4<br/>5</pre></td><td class="code"><pre class="highlight"><code><span class="n">linsvcBO</span> <span class="o">=</span> <span class="n">BayesianOptimization</span><span class="p">(</span>
        <span class="n">linsvccv</span><span class="p">,</span>
        <span class="p">{</span><span class="s">'C'</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10000</span><span class="p">),</span>
         <span class="s">'class_weight'</span><span class="p">:</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">)}</span>
    <span class="p">)</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1</pre></td><td class="code"><pre class="highlight"><code><span class="n">linsvcBO</span><span class="o">.</span><span class="n">maximize</span><span class="p">(</span><span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter</span><span class="p">,</span> <span class="o">**</span><span class="n">gp_params</span><span class="p">)</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1</pre></td><td class="code"><pre class="highlight"><code><span class="n">BO_log</span><span class="p">(</span><span class="n">linsvcBO</span><span class="p">,</span> <span class="s">'linsvc'</span><span class="p">)</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1</pre></td><td class="code"><pre class="highlight"><code><span class="n">linsvc_clf</span> <span class="o">=</span> <span class="n">linsvc</span><span class="p">(</span><span class="o">**</span><span class="n">linsvcBO</span><span class="o">.</span><span class="n">res</span><span class="p">[</span><span class="s">'max'</span><span class="p">][</span><span class="s">'max_params'</span><span class="p">])</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1</pre></td><td class="code"><pre class="highlight"><code><span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">linsvc_clf</span><span class="p">,</span> <span class="n">generate_filename</span><span class="p">(</span><span class="s">'linsvc_clf'</span><span class="p">))</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3</pre></td><td class="code"><pre class="highlight"><code><span class="n">linsvc_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">linsvc_pred</span> <span class="o">=</span> <span class="n">linsvc_clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test_scaled</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">linsvc_pred</span><span class="p">))</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1</pre></td><td class="code"><pre class="highlight"><code><span class="n">linsvc_oof_train</span><span class="p">,</span> <span class="n">linsvc_oof_test</span> <span class="o">=</span> <span class="n">get_oof</span><span class="p">(</span><span class="n">linsvc_clf</span><span class="p">,</span><span class="n">x_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test_scaled</span><span class="p">)</span>
</code></pre></td></tr></tbody></table></div>
</div>

<h4 id="mlp">MLP</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3<br/>4<br/>5<br/>6<br/>7<br/>8<br/>9<br/>10<br/>11</pre></td><td class="code"><pre class="highlight"><code><span class="k">def</span> <span class="nf">mlp</span><span class="p">(</span><span class="n">first_layer</span><span class="p">,</span> <span class="n">second_layer</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">MLPClassifier</span><span class="p">(</span>
            <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">first_layer</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">second_layer</span><span class="p">)),</span>
            <span class="n">alpha</span><span class="o">=</span><span class="mi">10</span><span class="o">**</span><span class="n">alpha</span>
        <span class="p">)</span>
<span class="k">def</span> <span class="nf">mlpccv</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">):</span>
    <span class="n">val</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span>
        <span class="n">mlp</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">),</span>
        <span class="n">x_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'f1'</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>
    <span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">val</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3<br/>4<br/>5<br/>6</pre></td><td class="code"><pre class="highlight"><code><span class="n">mlpcBO</span> <span class="o">=</span> <span class="n">BayesianOptimization</span><span class="p">(</span>
        <span class="n">mlpccv</span><span class="p">,</span>
        <span class="p">{</span><span class="s">'first_layer'</span><span class="p">:</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span>
         <span class="s">'second_layer'</span><span class="p">:</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
         <span class="s">'alpha'</span><span class="p">:</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)}</span>
    <span class="p">)</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1</pre></td><td class="code"><pre class="highlight"><code><span class="n">mlpcBO</span><span class="o">.</span><span class="n">maximize</span><span class="p">(</span><span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter</span><span class="p">,</span> <span class="o">**</span><span class="n">gp_params</span><span class="p">)</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1</pre></td><td class="code"><pre class="highlight"><code><span class="n">BO_log</span><span class="p">(</span><span class="n">mlpcBO</span><span class="p">,</span> <span class="s">'mlp'</span><span class="p">)</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1</pre></td><td class="code"><pre class="highlight"><code><span class="n">mlp_clf</span> <span class="o">=</span> <span class="n">mlp</span><span class="p">(</span><span class="o">**</span><span class="n">mlpcBO</span><span class="o">.</span><span class="n">res</span><span class="p">[</span><span class="s">'max'</span><span class="p">][</span><span class="s">'max_params'</span><span class="p">])</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1</pre></td><td class="code"><pre class="highlight"><code><span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">mlp_clf</span><span class="p">,</span> <span class="n">generate_filename</span><span class="p">(</span><span class="s">'mlp_clf'</span><span class="p">))</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3</pre></td><td class="code"><pre class="highlight"><code><span class="n">mlp_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">mlp_pred</span> <span class="o">=</span> <span class="n">mlp_clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test_scaled</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">mlp_pred</span><span class="p">))</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1</pre></td><td class="code"><pre class="highlight"><code><span class="n">mlp_oof_train</span><span class="p">,</span> <span class="n">mlp_oof_test</span> <span class="o">=</span> <span class="n">get_oof</span><span class="p">(</span><span class="n">mlp_clf</span><span class="p">,</span> <span class="n">x_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test_scaled</span><span class="p">)</span> 
</code></pre></td></tr></tbody></table></div>
</div>

<h2 id="stacking-base-models">Stacking Base Models</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3<br/>4<br/>5<br/>6<br/>7</pre></td><td class="code"><pre class="highlight"><code><span class="n">base_predictions_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">{</span><span class="s">'RandomForest'</span><span class="p">:</span> <span class="n">rf_oof_train</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
     <span class="s">'LightGBM'</span><span class="p">:</span> <span class="n">lgb_oof_train</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
     <span class="s">'LinSVC'</span><span class="p">:</span> <span class="n">linsvc_oof_train</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
     <span class="s">'MLP'</span><span class="p">:</span> <span class="n">mlp_oof_train</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
    <span class="p">})</span>
<span class="n">base_predictions_train</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>LightGBM</th>
      <th>LinSVC</th>
      <th>MLP</th>
      <th>RandomForest</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3<br/>4</pre></td><td class="code"><pre class="highlight"><code><span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">base_predictions_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
            <span class="n">xticklabels</span><span class="o">=</span><span class="n">base_predictions_train</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span>
            <span class="n">yticklabels</span><span class="o">=</span><span class="n">base_predictions_train</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span>
            <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></td></tr></tbody></table></div>
</div>

<p><img src="/img/in-post/stacking-template/output_58_1.png" alt="png" /></p>

<p>This heat map was taken from one of the randomly generated data I have run. In general, as mentioned by <a href="https://link.springer.com/content/pdf/10.1023%2FB%3AMACH.0000015881.36452.6e.pdf">Džeroski and Ženko</a>, it is a good idea to include heterogenous classifiers as base models for stacking, i.e. classifiers that use different model representations. Since both random forest and lightgbm are tree-based, their high correlation is expected.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3<br/>4<br/>5<br/>6<br/>7<br/>8<br/>9<br/>10</pre></td><td class="code"><pre class="highlight"><code><span class="n">xg_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">rf_oof_train</span><span class="p">,</span> 
                           <span class="n">lgb_oof_train</span><span class="p">,</span> 
                           <span class="n">linsvc_oof_train</span><span class="p">,</span> 
                           <span class="n">mlp_oof_train</span><span class="p">,</span> 
                          <span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">xg_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">rf_oof_test</span><span class="p">,</span> 
                          <span class="n">lgb_oof_test</span><span class="p">,</span> 
                          <span class="n">linsvc_oof_test</span><span class="p">,</span> 
                          <span class="n">mlp_oof_test</span><span class="p">,</span> 
                         <span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3<br/>4<br/>5<br/>6<br/>7<br/>8<br/>9<br/>10<br/>11<br/>12<br/>13<br/>14<br/>15<br/>16<br/>17<br/>18<br/>19<br/>20<br/>21<br/>22<br/>23<br/>24</pre></td><td class="code"><pre class="highlight"><code><span class="k">def</span> <span class="nf">xgb</span><span class="p">(</span><span class="n">max_depth</span><span class="p">,</span> 
          <span class="n">learning_rate</span><span class="p">,</span> 
          <span class="n">n_estimators</span><span class="p">,</span> 
          <span class="n">gamma</span><span class="p">,</span> 
          <span class="n">min_child_weight</span><span class="p">,</span> 
          <span class="n">subsample</span><span class="p">,</span>
          <span class="n">scale_pos_weight</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">XGBClassifier</span><span class="p">(</span>
            <span class="n">max_depth</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">max_depth</span><span class="p">),</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="n">n_estimators</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">n_estimators</span><span class="p">),</span>
            <span class="n">min_child_weight</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">min_child_weight</span><span class="p">),</span>
            <span class="n">gamma</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">gamma</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
            <span class="n">subsample</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">subsample</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">0</span><span class="p">),</span>
            <span class="n">scale_pos_weight</span><span class="o">=</span><span class="n">scale_pos_weight</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>
        <span class="p">)</span>
<span class="k">def</span> <span class="nf">xgbcv</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">):</span>
    <span class="n">val</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span>
        <span class="n">xgb</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">),</span>
        <span class="n">xg_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'f1'</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span>
    <span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">val</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3<br/>4<br/>5<br/>6<br/>7<br/>8<br/>9<br/>10<br/>11</pre></td><td class="code"><pre class="highlight"><code><span class="n">xgbBO</span> <span class="o">=</span> <span class="n">BayesianOptimization</span><span class="p">(</span>
        <span class="n">xgbcv</span><span class="p">,</span>
        <span class="p">{</span><span class="s">'max_depth'</span><span class="p">:</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
         <span class="s">'learning_rate'</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">),</span>
         <span class="s">'n_estimators'</span><span class="p">:(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">500</span><span class="p">),</span>
         <span class="s">'min_child_weight'</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span>
         <span class="s">'gamma'</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
         <span class="s">'subsample'</span><span class="p">:(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
         <span class="s">'scale_pos_weight'</span><span class="p">:(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="p">}</span>
    <span class="p">)</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1</pre></td><td class="code"><pre class="highlight"><code><span class="n">xgbBO</span><span class="o">.</span><span class="n">maximize</span><span class="p">(</span><span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter</span><span class="p">,</span> <span class="o">**</span><span class="n">gp_params</span><span class="p">)</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1</pre></td><td class="code"><pre class="highlight"><code><span class="n">BO_log</span><span class="p">(</span><span class="n">xgbBO</span><span class="p">,</span> <span class="s">'xgb'</span><span class="p">)</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1</pre></td><td class="code"><pre class="highlight"><code><span class="n">xgb_clf</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">(</span><span class="o">**</span><span class="n">xgbBO</span><span class="o">.</span><span class="n">res</span><span class="p">[</span><span class="s">'max'</span><span class="p">][</span><span class="s">'max_params'</span><span class="p">])</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1</pre></td><td class="code"><pre class="highlight"><code><span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">xgb_clf</span><span class="p">,</span> <span class="n">generate_filename</span><span class="p">(</span><span class="s">'xgb_clf'</span><span class="p">))</span>
</code></pre></td></tr></tbody></table></div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3</pre></td><td class="code"><pre class="highlight"><code><span class="n">xgb_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xg_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">xgb_pred</span> <span class="o">=</span> <span class="n">xgb_clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xg_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">xgb_pred</span><span class="p">))</span>
</code></pre></td></tr></tbody></table></div>
</div>

<h2 id="conclusion">Conclusion</h2>

<p>The aim of this template is to provide a quick set up of a stacking ensemble with bayesian optimization. Based on my work experience in fraud detection, finding the right features is much more important than building a fancy model. I believe that for most machine learning applications, the key to create the best model is thorough understanding of the problem so that one could figure out features that best describes the situation. I hope this template can save you some time in getting the model to work so that you can stay focused on the problem per se.</p>


      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            
            <a href="/tag/#/python" rel="tag"># python</a>
          
            
            <a href="/tag/#/machine%20learning" rel="tag"># machine learning</a>
          
        </div>
      

      
      
      
      
      

      
      
        <div class="post-nav" id="post-nav-id">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/11/12/SKLearn-Compatible-Classifier/" rel="next" title="Homemade sklearn Classifier">
                <i class="fa fa-chevron-left"></i> Homemade sklearn Classifier
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/11/07/3D-Interactive-Visualization-of-Graph/" rel="prev" title="3D Interactive Visualization of Graph">
                3D Interactive Visualization of Graph <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      
      

      
    </footer>
  </article>

  <div class="post-spread">
    
  </div>
</div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          

  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      
        
        
        







      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/assets/images/avatar.jpeg"
               alt="Shiki" />
          <p class="site-author-name" itemprop="name">Shiki</p>
           
              <p class="site-description motion-element" itemprop="description"> </p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">6</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/">
                <span class="site-state-item-count">4</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        
        
        

        <div class="links-of-author motion-element">
          
            
              
              
              <span class="links-of-author-item">
                <a href="https://github.com/Shiki-H" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            








            
              <div class="post-toc-content">
    <ol class=nav>
      <li class="nav-item nav-level-2"> <a class="nav-link" href="#introduction"> <span class="nav-number">1</span> <span class="nav-text">Introduction</span> </a> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#load-data"> <span class="nav-number">2</span> <span class="nav-text">Load Data</span> </a> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#stacking-preparations"> <span class="nav-number">3</span> <span class="nav-text">Stacking Preparations</span> </a> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#tuning-base-models"> <span class="nav-number">4</span> <span class="nav-text">Tuning Base Models</span> </a> <ol class="nav-child"> <li class="nav-item nav-level-4"> <a class="nav-link" href="#random-forest"> <span class="nav-number">4.1</span> <span class="nav-text">Random Forest</span> </a> </li> <li class="nav-item nav-level-4"> <a class="nav-link" href="#lightgbm"> <span class="nav-number">4.2</span> <span class="nav-text">LightGBM</span> </a> </li> <li class="nav-item nav-level-4"> <a class="nav-link" href="#svm"> <span class="nav-number">4.3</span> <span class="nav-text">SVM</span> </a> </li> <li class="nav-item nav-level-4"> <a class="nav-link" href="#mlp"> <span class="nav-number">4.4</span> <span class="nav-text">MLP</span> </a> </li> </ol> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#stacking-base-models"> <span class="nav-number">5</span> <span class="nav-text">Stacking Base Models</span> </a> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#conclusion"> <span class="nav-number">6</span> <span class="nav-text">Conclusion</span> </a> </li>
    </ol>
  </div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>

        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  
  &copy;  2017 - 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Shiki</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://jekyllrb.com">Jekyll</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/simpleyyt/jekyll-theme-next">
    NexT.Mist
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>





















  
   
  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/jquery/index.js?v=2.1.3"></script>

  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/assets/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/assets/js/src/motion.js?v=5.1.1"></script>



  
  

  <script type="text/javascript" src="/assets/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/assets/js/src/post-details.js?v=5.1.1"></script>


  


  <script type="text/javascript" src="/assets/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  











  




  

    

  





  






  

  

  
  


  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>

